{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":34595,"sourceType":"datasetVersion","datasetId":26922,"isSourceIdPinned":false}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow pillow numpy scikit-learn matplotlib pandas -q","metadata":{"id":"CKp9iP_fyV0n","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T12:24:58.206590Z","iopub.execute_input":"2025-09-20T12:24:58.207188Z","iopub.status.idle":"2025-09-20T12:25:01.466633Z","shell.execute_reply.started":"2025-09-20T12:24:58.207163Z","shell.execute_reply":"2025-09-20T12:25:01.465543Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"jessicali9530/lfw-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2Ri1UPeye-Q","outputId":"25a0b4d9-24a1-48e8-b09e-0f25c167ccd8","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T12:25:01.468583Z","iopub.execute_input":"2025-09-20T12:25:01.468936Z","iopub.status.idle":"2025-09-20T12:25:01.561928Z","shell.execute_reply.started":"2025-09-20T12:25:01.468886Z","shell.execute_reply":"2025-09-20T12:25:01.561413Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/lfw-dataset\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os\nimport random\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport os, random, math, glob, shutil\nfrom pathlib import Path\nfrom zipfile import ZipFile\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing import image as kimage\nfrom sklearn.model_selection import train_test_split\n\n# Set random seed\ntf.random.set_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n# Configure GPU memory growth\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    print('Using GPU:', gpus)\nelse:\n    print('Using CPU')\n\n# Dataset paths\nroot_dir = '/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\ncsv_dir = '/kaggle/input/lfw-dataset'","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V1wPc92NyiuT","outputId":"e5c78552-0c5f-40f1-edf1-e83947c1d1b3","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T12:25:01.562753Z","iopub.execute_input":"2025-09-20T12:25:01.563012Z","iopub.status.idle":"2025-09-20T12:25:01.586016Z","shell.execute_reply.started":"2025-09-20T12:25:01.562991Z","shell.execute_reply":"2025-09-20T12:25:01.585258Z"}},"outputs":[{"name":"stdout","text":"Using GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def semi_hard_triplet_loss(embed_anchor, embed_positive, embed_negative, margin=1.0):\n    d_ap = tf.reduce_sum(tf.square(embed_anchor - embed_positive), axis=1)\n    d_an = tf.reduce_sum(tf.square(embed_anchor - embed_negative), axis=1)\n    semi_hard_mask = tf.cast(tf.logical_and(d_ap < d_an, d_an < d_ap + margin), tf.float32)\n    loss = tf.maximum(0.0, d_ap - d_an + margin)\n    loss = loss * semi_hard_mask\n    valid_triplets = tf.reduce_sum(semi_hard_mask)\n    loss = tf.reduce_sum(loss) / tf.maximum(valid_triplets, 1e-10)\n    return loss\n\n\n# def triplet_loss(anchor, positive, negative, margin=0.2):\n#    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n#    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n#    loss = tf.maximum(pos_dist - neg_dist + margin, 0.0)\n#    return tf.reduce_mean(loss)","metadata":{"id":"xszzKg3d1SrH","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T12:25:01.587857Z","iopub.execute_input":"2025-09-20T12:25:01.588061Z","iopub.status.idle":"2025-09-20T12:25:01.602907Z","shell.execute_reply.started":"2025-09-20T12:25:01.588046Z","shell.execute_reply":"2025-09-20T12:25:01.602229Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def load_people_csv(csv_path):\n    df = pd.read_csv(csv_path)\n    return df[['name', 'images']].values.tolist()\n\ntrain_val_people = load_people_csv(os.path.join(csv_dir, 'peopleDevTrain.csv'))\ntest_people = load_people_csv(os.path.join(csv_dir, 'peopleDevTest.csv'))\n\n# Filter >=2 images, sort by image count, take top 100\ntrain_val_people = sorted([p for p in train_val_people if p[1] >= 2], key=lambda x: x[1], reverse=True)[:100]\ntest_people = sorted([p for p in test_people if p[1] >= 2], key=lambda x: x[1], reverse=True)[:100]\nprint(f'Train+Val persons: {len(train_val_people)}, Test persons: {len(test_people)}')\n\n# Split train_val\ntrain_people, val_people = train_test_split(train_val_people, test_size=0.2, random_state=42)\nprint(f'Train persons: {len(train_people)}, Val: {len(val_people)}')\n\ndef get_image_paths(root_dir, people_list):\n    image_paths = {}\n    for person, _ in people_list:\n        person_dir = os.path.join(root_dir, person)\n        if os.path.isdir(person_dir):\n            image_paths[person] = [os.path.join(person_dir, img) for img in os.listdir(person_dir) if img.endswith('.jpg')]\n    return image_paths\n\ntrain_image_paths = get_image_paths(root_dir, train_people)\nval_image_paths = get_image_paths(root_dir, val_people)\ntest_image_paths = get_image_paths(root_dir, test_people)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poklC-SkyfYe","outputId":"0350c859-2595-4ff8-8dc4-229753049250","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T12:25:01.603698Z","iopub.execute_input":"2025-09-20T12:25:01.603927Z","iopub.status.idle":"2025-09-20T12:25:01.863288Z","shell.execute_reply.started":"2025-09-20T12:25:01.603904Z","shell.execute_reply":"2025-09-20T12:25:01.862756Z"}},"outputs":[{"name":"stdout","text":"Train+Val persons: 100, Test persons: 100\nTrain persons: 80, Val: 20\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def preprocess_train(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [224, 224])\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_brightness(image, max_delta=0.2)\n    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n    image = image / 255.0\n    image = tf.keras.applications.resnet50.preprocess_input(image * 255.0)\n    return image\n\ndef preprocess_test(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [224, 224])\n    image = image / 255.0\n    image = tf.keras.applications.resnet50.preprocess_input(image * 255.0)\n    return image","metadata":{"id":"ZID0QO9cyfeh","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T12:25:01.863975Z","iopub.execute_input":"2025-09-20T12:25:01.864212Z","iopub.status.idle":"2025-09-20T12:25:01.869799Z","shell.execute_reply.started":"2025-09-20T12:25:01.864188Z","shell.execute_reply":"2025-09-20T12:25:01.869138Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def triplet_dataset(image_paths_dict, preprocess_fn, batch_size=8):\n    person_list = list(image_paths_dict.keys())\n    def generator():\n        while True:\n            anchor_person = random.choice(person_list)\n            if len(image_paths_dict[anchor_person]) < 2:\n                continue\n            anchor_path, positive_path = random.sample(image_paths_dict[anchor_person], 2)\n            negative_person = random.choice([p for p in person_list if p != anchor_person])\n            negative_path = random.choice(image_paths_dict[negative_person])\n            yield anchor_path, positive_path, negative_path\n    \n    dataset = tf.data.Dataset.from_generator(\n        generator,\n        output_types=(tf.string, tf.string, tf.string),\n        output_shapes=((), (), ())\n    )\n    dataset = dataset.map(\n        lambda a, p, n: (preprocess_fn(a), preprocess_fn(p), preprocess_fn(n)),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"id":"PMM46CUoyfkN","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T12:25:01.870795Z","iopub.execute_input":"2025-09-20T12:25:01.871024Z","iopub.status.idle":"2025-09-20T12:25:01.887734Z","shell.execute_reply.started":"2025-09-20T12:25:01.871000Z","shell.execute_reply":"2025-09-20T12:25:01.887002Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def create_backbone():\n    base_model = tf.keras.applications.ResNet50(\n        include_top=False,\n        weights='imagenet',\n        input_shape=(224, 224, 3)\n    )\n    for layer in base_model.layers[:143]: \n        layer.trainable = False\n    for layer in base_model.layers[143:]:\n        layer.trainable = True\n    x = base_model.output\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n #   x = tf.keras.layers.Dense(512, activation=None, dtype='float32')(x)\n    x = tf.keras.layers.Dense(512, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation = None, dtype='float32')(x)\n#   x = tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1),output_shape=(512,))(x)\n    x = tf.keras.layers.UnitNormalization(axis=1)(x)\n    return tf.keras.Model(inputs=base_model.input, outputs=x)\n\nbackbone = create_backbone()\n\ndef forward_one(image):\n    return backbone(image)\n\ndef forward_triplet(anchor, positive, negative):\n    embed_anchor = forward_one(anchor)\n    embed_positive = forward_one(positive)\n    embed_negative = forward_one(negative)\n    return embed_anchor, embed_positive, embed_negative","metadata":{"id":"sRMRegJVyfn5","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T12:25:01.888605Z","iopub.execute_input":"2025-09-20T12:25:01.888879Z","iopub.status.idle":"2025-09-20T12:25:03.226705Z","shell.execute_reply.started":"2025-09-20T12:25:01.888838Z","shell.execute_reply":"2025-09-20T12:25:03.225917Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n\n@tf.function\ndef train_step(anchor, positive, negative):\n    with tf.GradientTape() as tape:\n        embed_a, embed_p, embed_n = forward_triplet(anchor, positive, negative)\n        loss = semi_hard_triplet_loss(embed_a, embed_p, embed_n, margin=0.75)\n    gradients = tape.gradient(loss, backbone.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, backbone.trainable_variables))\n    return loss\n    \n@tf.function\ndef val_step(anchor, positive, negative):\n    embed_a, embed_p, embed_n = forward_triplet(anchor, positive, negative)\n    loss = semi_hard_triplet_loss(embed_a, embed_p, embed_n, margin=0.75)\n    return loss\n\ndef train_epoch(dataset, num_batches=100):\n    total_loss = 0.0\n    iterator = iter(dataset)\n    for _ in range(num_batches):\n        anchor, positive, negative = next(iterator)\n        loss = train_step(anchor, positive, negative)\n        total_loss += loss.numpy()\n        tf.keras.backend.clear_session()\n        gc.collect()\n    return total_loss / max(1, num_batches)\n\ndef val_epoch(dataset, num_batches=100):\n    total_loss = 0.0\n    iterator = iter(dataset)\n    for _ in range(num_batches):\n        anchor, positive, negative = next(iterator)\n        loss = val_step(anchor, positive, negative)\n        total_loss += loss.numpy()\n        tf.keras.backend.clear_session()\n        gc.collect()\n    return total_loss / max(1, num_batches)","metadata":{"id":"33TM5V1iyfvA","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T12:25:03.228365Z","iopub.execute_input":"2025-09-20T12:25:03.228626Z","iopub.status.idle":"2025-09-20T12:25:03.241500Z","shell.execute_reply.started":"2025-09-20T12:25:03.228608Z","shell.execute_reply":"2025-09-20T12:25:03.240863Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import gc\nnum_epochs = 8\nbatch_size = 32\ntrain_losses = []\nval_losses = []\nnum_batches_per_epoch = 100\n\n#early_stopping = tf.keras.callbacks.EarlyStopping(\n#    monitor='val_loss',\n#    patience=2,\n#    restore_best_weights=True,\n#    verbose=1\n#)\n\nfor epoch in range(num_epochs):\n    train_dataset = triplet_dataset(train_image_paths, preprocess_train, batch_size=batch_size)\n    val_dataset = triplet_dataset(val_image_paths, preprocess_test, batch_size=batch_size)\n    train_loss = train_epoch(train_dataset, num_batches_per_epoch)\n    val_loss = val_epoch(val_dataset, num_batches_per_epoch)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    print(f'Epoch {epoch+1}/{num_epochs}: Train Loss {train_loss:.4f}, Val Loss {val_loss:.4f}')\n #   early_stopping.on_epoch_end(epoch, logs={'val_loss': val_loss})\n #   if early_stopping.stopped_epoch > 0:\n #       print(f\"Early stopping triggered at epoch {early_stopping.stopped_epoch + 1}\")\n #       break\n    tf.keras.backend.clear_session()\n    gc.collect()\n\nbackbone.save('/kaggle/working/siamese_try_6.keras')\nprint('Model saved')\n\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\nplt.plot(range(1, num_epochs+1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Losses')\nplt.savefig('/kaggle/working/losses_plot_try_6.png')\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YI37Gx2Jyf0J","outputId":"32c48240-9b95-4a37-f41a-bbcf4030c3ff","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T13:41:13.658969Z","iopub.execute_input":"2025-09-20T13:41:13.659673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'losses_plot_try_5.png')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-20T07:46:22.602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'siamese_try_5.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T10:40:27.805720Z","iopub.execute_input":"2025-09-20T10:40:27.806358Z","iopub.status.idle":"2025-09-20T10:40:27.810882Z","shell.execute_reply.started":"2025-09-20T10:40:27.806336Z","shell.execute_reply":"2025-09-20T10:40:27.810349Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/siamese_try_5.keras","text/html":"<a href='siamese_try_5.keras' target='_blank'>siamese_try_5.keras</a><br>"},"metadata":{}}],"execution_count":11}]}